\documentclass[../draft_1.tex]{subfiles}

\begin{document}

\chapter{Prologue}

In this thesis we  discuss and develop \textit{adaptive} multigrid solvers for space-time discretisations of parabolic reaction diffusion equations with a potentially nonlinear forcing term. They present a broad class of partial differential equations that can be written in the form
\begin{ceqn}
\begin{equation}
u_t - div ( D(x) \nabla u) = f(u)
\end{equation}
\end{ceqn}
for some $u = u(x,t)$ in a space domain over a time interval in addition to a set of boundary conditions. We will postpone more rigorous definitions to the following chapters and for now simply assume the problem to be well posed. This type of equations is used to describe a variety of physical phenomena. In its simplest form we have a zero source term, that is $f = 0$. This heat equation describes the variation of temperature in a particular region over time starting from a set of initial conditions which will eventually reach an equilibrium state. Other important applications are the transformation of one or more chemical substances into another over time, the development of animal populations in biology \cite{cosner2008reaction} or the propagation of wavefronts \cite{zegeling2004adaptive}. A particular instance of a traveling wave which we will particularly focus on and which originally motivated the topic of this thesis, is the propagation of electric signals in human heart tissue. It can be modeled using the so-called monodomain equations which are also a reaction-diffusion system \cite{franzone2014mathematical}. The contraction of our heart is governed by an electric impulse whose charge distribution travels as a wavefront through our cell tissue. When trying to numerically approximate such a process one faces a number of challenges. One of the main difficulties that arises is the multiscale range in space and time \cite{colli2004parallel}. The overall space and time domain are very large compared to the rapid local changes of the current potential in the wavefront which therefore require a high accuracy in time and several space dimensions. Therefore \textit{representative} discretisations result in large systems of equations involving \textit{extensive} numbers of degrees of freedom. Solving them in an accurate, robust and efficient way has been and continuous being an extensive area of interest and research [source]. 
\smallskip
\\
In general when trying to numerically approximate the solution of a partial differential equation there is no unique way to do so and hence many design choices have to be made. A very important one includes the way of how to discretise the domain [source]. A frequently used possibility is the method of lines approach, where first the space is discretised e.g. using finite elements and where the time variable remains continuous which will give rise to a system of ordinary differential equations that is then to be solved by an appropriate method [source]. A very common approach is to use a time stepping method [source]. That is one computes an approximation for all space elements or nodes at a certain time $t_n$ and then uses those results or even preceding ones to compute the approximate solution at the next time $t_{n+1}$. This is the natural way to perform operations, because this is also how we move through time, sequentially, causality implies that the solution at a given time depends on the previous one but not the other way around. 
However in current technological development where there is no further significant increase in CPU clockspeed, the only way to really achieve a gain in computational power is through an increase in the number of processors. Therefore for this to actually translate to a computational speed up one requires algorithms to be more and more parallelisable, that is to allow for more operations to be performed at the same time. The approach outlined above contains inherently sequential processes, since only the space dimensions allow for parallelisation. As this saturates [source] there is no possibility for a further speed up. Thus it makes sense to look for methods that utilise a parallelisation in space and time simultaneously. This in turn naturally leads to a space-time discretisation of the equation as a whole \cite{gander201550}, which is also what we will be considering in this thesis, a large space-time system which we want to be able to mainly solve in parallel. A short discussion of the research done on this field so far, advantages and difficulties as well as some further references can be found in section 3.1., while the particular discretisation we chose will be introduced in chapter 4.
\bigskip
\\
It has been shown that large linear systems of equations are often most efficiently solved using iterative schemes [source]. Among them, multigrid methods represent an important and powerful class to approximate such solutions. In the case of sparse, symmetric, positive definite systems they even provide optimality in the sense that their complexity can be bounded by $O(N)$, where $N$ is the number of degrees of freedom \cite{brandt1977multi}. Unfortunately the behavior of multigrid algorithms in an indefinite or not symmetric setting is often not yet very well understood or not suitable [source], and convergence is generally not guaranteed [source]. Therefore we would like to aim for the construction of a system that can claim as many of these preferrable properties as possible. However most space-time solution methods do not give rise to symmetric positive definite systems \cite{gander201550} which is why we recast problem (1.1) as an optimisation probelm, an ansatz known as least squares finite element methods \cite{bochev2009least} and which will be first introduced in section 3.4. It entails the construction of a minimisation problem whose solution coincides with the solution of the differential equation. Instead of solving the original problem we now apply a finite element approach in space-time to solve the auxiliary problem whose value for a given input $u$ denotes an energy that we can minimise. In the linear case we are, due to the symmetry and positive definiteness of the system, guaranteed the existence of a global minimiser. In the nonlinear case we consider linearisations of the system which are generally not positive definite, but the symmtetry is maintained because of the commutativity of derivatives. The problem is non-convex but by successively reducing energy we can still find local minima. Hence for a nonlinear source or reaction term $f$, we additionally require an outer nonlinear iteration scheme which succuessively solves linearisations of the least squares functional. The non-linear solvers that were employed in the implementation section here are a damped Newton method \cite{deuflhard2011newton} and a trust region method \cite{conn2000trust}, and will be introduced in section 3.2. We have convergence to a global minimiser in a neighbourhood of the solution, that is for a sufficiently good initial starting iterate the solution of the original problem is recovered.
\smallskip
\\
Below we can see a schematic overview of how these beforementioned core concepts are tied together in order to give rise to a comprehensive \textit{solver}.

\begin{framed}
	\underline{\textbf{Overview of the different Steps towards an Approximate Solution}} 
	
	\begin{enumerate}
		\item  Reformulate (1.1) as a mimimisation problem $J$ whose solution coincides with the one of the original equation. 
		\item Discretise the problem using a space-time finite element approach
		\item Derive a non-linear iteration scheme (e.g. Newton or Trust Region method) where we solve a linearisation of the problem using the current iterative solution in each step
		\item  Solve the arising linear system of equations using a multigrid method
		\item Repeat step 4 with the updated solution each time until a stopping criterion is met 
	\end{enumerate}	
\end{framed}


These are the main ingredients that we will tie together in this thesis in order to develop an efficient, robust and accurate solver to tackle problems of type (1.1). It is a rather novel construction that has, to our knowledge, not been studied in this context and will therefore require further investigations before drawing any final conclusions on its utility. The mathematical methodologies will be introduced more thoroughly in chapter 3, where we will also explain the particular choice for each of them in more detail, attempting to make use of their favourable properties while trying to avoid the pitfalls. In chapter 4 we derive a proper problem formulation, which we will then discretise in order to derive linear systems of equations to be solved iteratively. Afterwards we introduce multrigrid methods in chapter 5, especially discussing the particularities that arise due to the construction presented in chapter 4. Chapter 6 then contains the numerical results we obtained for various test cases and discusses certain behaviors we observed during our work which will then be followed by a conclusion and an outlook in chapter 7. 
\bigskip
\\ 
In order to really obtain a meaningful solution $u$ we need a number of properties to be fulfilled. In each nonlinear iteration step the multigrid solver has to converge to the solution of the linearised least squares minimisation problem. In the outer iteration we need the nonlinear iteration scheme to converge to the minimiser of our non-linear functional whose solution as mentioned above is supposed to correspond to the solution of the original problem. However we are not ensured global convergence since the problem is in general non-convex. 
\bigskip
\\
Overall we are aiming for a better understanding of the versatility of space-time least squares finite element approaches in general and in combination with multigrid methods. \textit{A focus will be given to the construction of a particular algebraic multigrid method that takes intrinsic properties related to the monodomain equation into account, developing an equally accurate but more efficient way through an adapted coarse grid construction.} To allow for a better understanding of the processes involved in this particular application the following chapter will give a brief insight into the functioning of the human heart, the transmission of electric potential through tissue, the different charge distribution within or between cells or cellular structures and how this can be turned into a mathematical model. 


\end{document}
