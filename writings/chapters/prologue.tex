\documentclass[../draft_1.tex]{subfiles}

\begin{document}

\chapter{Prologue}

In this thesis we  discuss and develop adaptive multigrid solvers for space-time discretisations of parabolic reaction diffusion equations with a potentially nonlinear forcing term. They present a broad class of partial differential equations that can be written in the form
\begin{ceqn}
\begin{equation}
u_t - div ( D(x) \nabla u) = f(u)
\end{equation}
\end{ceqn}
for some $u = u(x,t)$ in a space domain over a time interval in addition to a set of boundary conditions. We will postpone more rigorous definitions to the following chapters and for now simply assume the problem to be well posed. This type of equations is used to describe a variety of physical phenomena, among which there are the reaction of one or more chemical substances into another over time as well as the propagation of wavefronts \cite{zegeling2004adaptive} which will be discussed in detail later or the development of animal populations in biology \cite{cosner2008reaction}. In its simplest form we have a zero source term, that is $f = 0$. This heat equation describes the variation of temperature in a particular region over time starting from a set of initial conditions which will eventually reach an equilibrium state.
Another process that can be described by an equation of the above type which we will particularly focus on and which originally motivated the topic of this thesis, is the propagation of electric signals in human heart tissue. It can be modeled using the so-called monodomain equations which are also a reaction-diffusion system. The contraction of our heart is governed by an electric impulse whose charge distribution travels as a wavefront through our cell tissue. When trying to numerically approximate such a process one faces a number of challenges. One of the main difficulties that arises is the multiscale range in space and time. The overall space and time domain are very large compared to the rapid local changes of the current potential in the wavefront which therefore require a high accuracy in time and several space dimensions. Therefore \textit{good} discretisations result in large systems of equations involving \textit{large} numbers of degrees of freedom. Solving them in an accurate, robust and efficient way has been and continuous being an extensive area of interest [source]. 
\smallskip
\\
In general when trying to numerically approximate the solution of a partial differential equation there is no unique way to do so and hence many design choices have to be made. A very important one includes the way of how to discretise the domain. A well-used possibility is the method of lines approach, where first the spatial derivatives are discretised and the time variables remain continuous which will give rise to a system of ordinary differential equations that is then to be solved by an appropriate method [source]. Another very common approach is using a time stepping method in combination with for example a finite element discretisation in space [source], that is one computes an approximation for all space elements or nodes at a certain time $t_n$ and then uses those results or even preceding ones to compute the approximate solution at the next time $t_{n+1}$. This can be considered the natural way to perform operations, because this is how we move through time, sequentially, additionally the solution at a given time usually depends on the previous one but not the other way around. 
However in current technological development where there is no further significant increase in clockspeed the only way to really gain computational power is through an increase in the number of processors. Therefore for this to actually translate to a computational speed up one requires algorithms to be more and more parallelisable, that is to allow for more operations to be performed at the same time. Both methodologies mentioned above contain inherently sequential processes. As for example for the later one as the spatial parallelisation becomes saturated [source] there is no possibility for a further speed up. Thus it computationally only makes sense to look for methods that utilise a parallelisation in space and time simultaneously. This in turn naturally invites for a space-time discretisation of the system as a whole [source]. A further discussion of the research done on this field so far, advantages and difficulties as well as some references can be found in section 3.1. Hence this is also what we will be considering in this thesis, space-time systems which we want to be able to solve mainly in parallel. 
\smallskip
\\
It has shown that large linear systems of equations are often most efficiently solved using iterative schemes [source], among them multigrid methods represent an important and powerful class to approximate such solutions. In the case of sparse, symmetric, positive definite systems they are even optimal in the sense that their complexity can be bounded by $o(N)$, where $N$ is the number of degrees of freedom. Unfortunately the behavior of multigrid algorithms in an indefinite or not symmetric setting is not yet very well understood [source], and convergence is generally not guaranteed [source]. Therefore we would like to aim for the construction of a system that can claim as many of these preferrable properties as possible. Often space-time solution methods do not give rise to symmetric positive definite systems [source] which is why we recast problem (1.1) as an optimisation probelm of a functional, an ansatz known as least squares finite element methods. Hence we will define a minimisation problem whose solution coincides with the solution of the differential equation. Instead of solving the original problem we now apply a finite element approach in space-time to solve the auxiliary problem whose value for a given input $u$ denotes an energy that we can minimise over. In the linear case we are due to the symmetry and positive definiteness guaranteed the existence of a global minimiser. In the nonlinear case the system is generally not positive definite, but the symmtetry is maintained because of the commutativity of the derivative, and we can at least guarantee the convergence to a local minimum. Hence we have convergence to the global minimiser in a neighbourhood of the solution, which means determining a good initial starting it iterate is essential. This means for a nonlinear source or reaction term $f$, we additionally require an outer nonlinear iteration scheme which succuessively solves linearisations of the least squares functional. The non-linear solvers that were employed in the implementation section here are a trust region method and a damped Newton method.
\smallskip
\\
These are the main ingredients that we will tie together in this thesis in order to develop an efficient, robust and accurate solver to tackle problems of type (1.1). Each of them will be introduced more thoroughly in chapter 3, where we will also explain the particular choice for each of them in more detail, attempting to make use of their favourable properties while trying to avoid the pitfalls. In chapter 4 we derive a proper problem formulation, which we will then discretise in order to derive linear systems of equations to be solved iteratively. Afterwards we introduce multrigrid methods in chapter 5, especially discussing the particularities that arise due to the construction presented in chapter 4. Chapter 6 then contains the numerical results we obtained for various test cases and discusses certain behaviors we observed during our work which will then be followed by a conclusion and an outlook in chapter 7. 
\smallskip
\\ 
Below we can see a schematic overview of how these beforementioned core concepts are tied together in order to give rise to a comprehensive \textit{solver} whose rather novel construction that has to our knowledge not been studied in this context and will therefore require further investigations before drawing any final conclusions on its utility.

\begin{framed}
	\underline{\textbf{Overview of the different Steps towards an Approximate Solution}} 
	
	\begin{enumerate}
		\item  Reformulate (1.1) as a mimimisation problem $J$ whose solution coincides with the one of the original equation. 
		\item Discretise the problem using a space-time finite element approach
		\item Derive a non-linear iteration scheme (e.g. Newton or Trust Region method) where we solve a linearisation of the problem using the current iterative solution in each step
		\item  Solve the arising linear system of equations using an adaptive multigrid method
		\item Repeat step 4 with the updated solution each time until some stopping criterion is met 
	\end{enumerate}	
\end{framed}

In order to obtain a meaningful solution $u$ we need a number of properties to be fulfilled. In each nonlinear iteration step the multigrid solver has to converge to the solution of the linearised least squares minimisation problem. In the outer iteration we need the nonlinear iteration scheme to converge to the minimiser of our non-linear functional whose solution as mentioned above is supposed to correspond to the solution of the original problem. However we are not ensured global convergence since the problem is in general non convex. 
\bigskip
\\
Overall we are aiming for a better understanding of the versality of space-time least squares finite element approaches in general and in combination with multigrid methods. But then an additional focus will be given to the construction of a particular algebraic multigrid method that takes intrinsic properties related to the monodomain equation into account, developing an equally accurate but more efficient way through an adapted coarse grid construction. To allow for a better overall understanding of the processes involved in this particular application the following chapter will give a brief insight into the functioning of the human heart, the transmission of electric potential through tissue, the different charge distribution within or between cells or cellular structures and how this can be turned into a mathematical model. 



\end{document}
