\documentclass[../draft_1.tex]{subfiles}

\begin{document}

\chapter{Prologue}

In this thesis we  discuss and develop \textit{adaptive} multigrid solvers for space--time discretisations of parabolic reaction diffusion equations with a potentially nonlinear forcing term. The latter present a broad class of partial differential equations that can be written in the form
\begin{ceqn}
\begin{equation}
\label{base_equation}
\partial_t u - \di ( D(x) \nabla u) = f(u)
\end{equation}
\end{ceqn}
for some $u = u(x,t)$ in a space domain over a time interval. We will postpone more rigorous definitions to the following chapters and for now simply assume the problem to be well posed which includes appropriately defined boundary conditions. This type of partial differential equation is used to describe a variety of physical phenomena. In its simplest form, we have a zero source term, i.e. $f = 0$. The resulting heat equation describes the variation of temperature in the space domain over time starting from a set of initial conditions. Other important applications with non-zero source terms, that can be described by (\ref{base_equation}), are chemical reactions over time, the development of populations in \cite{cosner2008reaction} or the propagation of wavefronts \cite{zegeling2004adaptive}. 
\smallskip
\\
A particular instance of a traveling wave which we will particularly focus on and which originally motivated the topic of this thesis, is the propagation of electric signals in heart tissue. It can be modeled using the so-called monodomain equations which are also a reaction-diffusion system \cite{franzone2014mathematical}. The contraction of our heart is governed by an electric impulse whose charge distribution is a wavefront front through our cell tissue. When trying to numerically approximate such a process one faces a number of challenges. One major challenge that arises is the multiscale range in space and time \cite{colli2004parallel}. The overall domain in space and time is very large compared to the characteristic length-scale on which the rapid local changes of the current potential occur. Thus one requires a high accuracy in time and space. Accurate discretisations result in large systems of equations involving large numbers of degrees of freedom. Solving them in an robust and efficient way is an active area of interest and research \cite{hohmann2012numerical}. 
\smallskip
\\
In general when trying to numerically approximate the solution of a partial differential equation there is no unique way to do so and hence many design choices have to be made. A frequently used possibility is the method of lines approach, where one first discretises in space  e.g. using finite elements and where the time variable remains continuous, which results in a system of ordinary differential equations that is then to be solved by an appropriate method [source]. A very common approach is to use a time stepping method [source]. That is one computes an approximation for all space elements or nodes at a certain time $t_n$ and then uses those results or even preceding ones to compute the approximate solution at the next time $t_{n+1}$. This is the natural way to perform operations, because this is also how we move through time, sequentially, causality implies that the solution at a given time depends on the previous one but not the other way around. 
However in current technological development where there is no further significant increase in CPU clockspeed, the only way to really achieve a gain in computational power is through an increase in the number of processors. Therefore for this to actually translate to a computational speed up one requires algorithms to be more and more parallelisable, that is to allow for more operations to be performed at the same time. The time stepping approach outlined above contains inherently sequential processes, since only the space dimensions allow for parallelisation. As this saturates [source] there is no possibility for a further speed up. Thus it makes sense to look for methods that utilise a parallelisation in space and time simultaneously. This in turn naturally leads to a space--time discretisation of the equation as a whole \cite{gander201550}, which is also what we will be considering in this thesis, a large space--time system which we want to be able to mainly solve in parallel. A short discussion of the research done on this field so far, advantages and difficulties as well as some further references can be found in Section 3.1., while the particular discretisation we chose will be introduced in chapter 4.
\bigskip
\\
It has been shown that large linear systems of equations are often most efficiently solved using iterative schemes [source]. Among them, multigrid methods represent an important and powerful class to approximate such solutions. In the case of sparse, symmetric, positive definite systems they even provide optimality in the sense that their complexity can be bounded by $O(N)$, where $N$ is the number of degrees of freedom \cite{brandt1977multi}. Unfortunately the behavior of multigrid algorithms in an indefinite or not symmetric setting is often not yet very well understood or not suitable [source], and convergence is generally not guaranteed [source]. Therefore we would like to aim for the construction of a system that can claim as many of these preferrable properties as possible. However most space-time solution methods do not give rise to symmetric positive definite systems \cite{gander201550} which is why we recast problem (1.1) as an optimisation probelm, an ansatz known as least squares finite element methods \cite{bochev2009least} and which will be first introduced in Section 3.4. It entails the construction of a minimisation problem whose solution coincides with the solution of the differential equation. Instead of solving the original problem we now apply a finite element approach in space-time to solve the auxiliary problem whose value for a given input $u$ denotes an energy that we can minimise. In the linear case we are, due to the symmetry and positive definiteness of the system, guaranteed the existence of a global minimiser. In the nonlinear case we consider linearisations of the system which are generally not positive definite, but the symmtetry is maintained because of the commutativity of derivatives. The problem is non-convex but by successively reducing energy we can still find local minima. Hence for a nonlinear source or reaction term $f$, we additionally require an outer nonlinear iteration scheme which succuessively solves linearisations of the least squares functional. The non-linear solvers that were employed in the implementation section here are a damped Newton method \cite{deuflhard2011newton} and a trust region method \cite{conn2000trust}, and will be introduced in Section 3.2. We have convergence to a global minimiser in a neighbourhood of the solution, that is for a sufficiently good initial starting iterate the solution of the original problem is recovered.
\smallskip
\\
Below we can see a schematic overview of how these beforementioned core concepts are tied together in order to give rise to a comprehensive solution method.

\begin{framed}
	\underline{\textbf{Overview of the different Steps towards an Approximate Solution}} 
	
	\begin{enumerate}
		\item  Reformulate (1.1) as a mimimisation problem $J$ whose solution coincides with the one of the original equation. 
		\item Discretise the problem using a space-time finite element approach
		\item Derive a nonlinear iteration scheme or energy minimisation method (e.g. Newton or Trust Region method) where we solve a simplified problem using the current iterative solution in each step
		\item  Solve the arising linear system of equations using a multigrid method
		\item Repeat Step 4 with the updated solution until a stopping criterion is met 
	\end{enumerate}	
\end{framed}

These are the main ingredients that we will tie together in this thesis in order to develop an efficient, robust and accurate solver to tackle problems of type (\ref{base_equation}). It is a rather novel construction that has, to our knowledge, not been studied in this context and will therefore require further investigations before drawing any final conclusions on its utility. The mathematical methodologies will be introduced more thoroughly in Chapter 3, where we will also explain the particular choice for each of them in more detail, attempting to make use of their favourable properties while trying to avoid the pitfalls. In Chapter 4 we derive a proper problem formulation, which we will then discretise in order to derive linear systems of equations to be solved iteratively. Afterwards we introduce multrigrid methods in Chapter 5, especially discussing the particularities that arise due to the construction presented in Chapter 4. Chapter 6 then contains the numerical results we obtained for various test cases and discusses certain behaviors we observed during our work which will then be followed by a conclusion and an outlook in Chapter 7. 
\bigskip
\\ 
In order to really obtain a meaningful solution $u$ we need a number of properties to be fulfilled. In each nonlinear iteration step the multigrid solver has to converge to the solution of the linearised least squares minimisation problem. In the outer iteration we need the nonlinear iteration scheme to converge to the minimiser of our non-linear functional whose solution as mentioned above is supposed to correspond to the solution of the original problem. However we are not ensured global convergence since the problem is in general non-convex. 
\bigskip
\\
Overall we are aiming for a better understanding of the versatility of space-time least squares finite element approaches in general and in combination with multigrid methods. \textit{A focus will be given to the construction of a particular algebraic multigrid method that takes intrinsic properties related to the monodomain equation into account, developing an equally accurate but more efficient way through an adapted coarse grid construction.} To allow for a better understanding of the processes involved in this particular application the following chapter will give a brief insight into the functioning of the human heart, the transmission of electric potential through tissue, the different charge distribution within or between cells or cellular structures and how this can be turned into a mathematical model. 


\end{document}
